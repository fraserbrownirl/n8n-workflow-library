{
  "meta": {
    "instanceId": "558d88703fb65b2d0e44613bc35916258b0f0bf983c5d4730c00c424b77ca36a",
    "templateCredsSetupCompleted": true
  },
  "nodes": [
    {
      "id": "6b47ec70-22fc-46eb-970f-57d43f1512ea",
      "name": "MCP Server Trigger",
      "type": "@n8n/n8n-nodes-langchain.mcpTrigger",
      "position": [
        0,
        0
      ],
      "webhookId": "f88b9b77-40f2-4fad-8e14-0fc7faed7a0b",
      "parameters": {
        "path": "f88b9b77-40f2-4fad-8e14-0fc7faed7a0b"
      },
      "typeVersion": 2
    },
    {
      "id": "cda97a99-fd6a-42dd-ba61-09af42f03112",
      "name": "Qdrant Vector Store",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "position": [
        140,
        200
      ],
      "parameters": {
        "mode": "retrieve-as-tool",
        "options": {},
        "toolDescription": "Use this tool to fetch information about MCP (Model Context Protocol)",
        "qdrantCollection": {
          "__rl": true,
          "mode": "id",
          "value": "MCP_RAG"
        }
      },
      "credentials": {
        "qdrantApi": {
          "id": "sFfERYppMeBnFNeA",
          "name": "Local QdrantApi database"
        }
      },
      "typeVersion": 1.3
    },
    {
      "id": "638d581b-7d35-4da2-8733-5960d151b711",
      "name": "Embeddings Ollama",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOllama",
      "position": [
        320,
        420
      ],
      "parameters": {
        "model": "mxbai-embed-large:latest"
      },
      "credentials": {
        "ollamaApi": {
          "id": "xHuYe0MDGOs9IpBW",
          "name": "Local Ollama service"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "3ff5792d-2991-40bc-8fde-b8dc5baacef6",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -180,
        -100
      ],
      "parameters": {
        "color": 4,
        "width": 680,
        "height": 640,
        "content": "## MCP Server\n**Our RAG MCP Server"
      },
      "typeVersion": 1
    },
    {
      "id": "18b55010-f395-429d-9b00-5b1ec50b236b",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        540,
        -100
      ],
      "parameters": {
        "color": 3,
        "width": 800,
        "height": 640,
        "content": "## RAG Ingestion Pipeline\n**Use this to ingest documents"
      },
      "typeVersion": 1
    },
    {
      "id": "96f2aa5e-8651-4f6a-bf2a-9fe954812a23",
      "name": "On form submission",
      "type": "n8n-nodes-base.formTrigger",
      "position": [
        620,
        0
      ],
      "webhookId": "0058bc22-8c8d-41ac-91db-c701a7ce1462",
      "parameters": {
        "options": {},
        "formTitle": "Add documents to RAG",
        "formFields": {
          "values": [
            {
              "fieldType": "file",
              "fieldLabel": "PDF File",
              "requiredField": true,
              "acceptFileTypes": ".pdf"
            }
          ]
        },
        "formDescription": "Click here to add documents to the semantic database"
      },
      "typeVersion": 2.2
    },
    {
      "id": "7066b3bc-b2ad-4d91-8104-1b59222932a1",
      "name": "Qdrant Vector Store1",
      "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "position": [
        840,
        0
      ],
      "parameters": {
        "mode": "insert",
        "options": {},
        "qdrantCollection": {
          "__rl": true,
          "mode": "id",
          "value": "MCP_RAG"
        }
      },
      "credentials": {
        "qdrantApi": {
          "id": "sFfERYppMeBnFNeA",
          "name": "Local QdrantApi database"
        }
      },
      "typeVersion": 1.3
    },
    {
      "id": "463a09b8-43ce-4427-88c6-ac54d5d705c7",
      "name": "Default Data Loader",
      "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "position": [
        1080,
        220
      ],
      "parameters": {
        "options": {},
        "dataType": "binary"
      },
      "typeVersion": 1.1
    }
  ],
  "pinData": {},
  "connections": {
    "Embeddings Ollama": {
      "ai_embedding": [
        [
          {
            "node": "Qdrant Vector Store",
            "type": "ai_embedding",
            "index": 0
          },
          {
            "node": "Qdrant Vector Store1",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "On form submission": {
      "main": [
        [
          {
            "node": "Qdrant Vector Store1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Default Data Loader": {
      "ai_document": [
        [
          {
            "node": "Qdrant Vector Store1",
            "type": "ai_document",
            "index": 0
          }
        ]
      ]
    },
    "Qdrant Vector Store": {
      "ai_tool": [
        [
          {
            "node": "MCP Server Trigger",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    }
  },
  "_metadata": {
    "name": "Build a Question-Answering AI Agent with Llama, RAG and Google Search",
    "used_count": 0,
    "popularity_score": 25,
    "source_url": "https://n8n.io/workflows/5403",
    "scraped_at": "2025-08-21 00:23:31",
    "workflow_id": "7e2c6b6a-bae9-5f28-ba98-bc3aa875e758"
  },
  "_filename": "Build_a_Question_Answering_AI_Agent_with_Llama_RAG_and_Google_Search.json"
}