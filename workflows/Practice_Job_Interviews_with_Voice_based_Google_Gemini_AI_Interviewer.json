{
  "id": "8N6ckeC2TziirGLt",
  "meta": {
    "instanceId": "e37465823f6ec6359565a2d8959871ac9f31984acb057f2daf8d42b2a65baea0",
    "templateCredsSetupCompleted": true
  },
  "name": "AI-voice-interviewer",
  "tags": [],
  "nodes": [
    {
      "id": "3a21db35-9973-472a-93f9-b8a2ba3175f2",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "position": [
        -368,
        -16
      ],
      "webhookId": "df27691d-564e-4207-8d9f-26a239f7a410",
      "parameters": {
        "path": "df27691d-564e-4207-8d9f-26a239f7a410",
        "options": {},
        "httpMethod": "POST",
        "responseMode": "responseNode"
      },
      "typeVersion": 2
    },
    {
      "id": "71fe1f4b-bb7e-4cd1-be2a-4e3988a172e7",
      "name": "If",
      "type": "n8n-nodes-base.if",
      "position": [
        -48,
        -64
      ],
      "parameters": {
        "options": {},
        "conditions": {
          "options": {
            "version": 2,
            "leftValue": "",
            "caseSensitive": true,
            "typeValidation": "strict"
          },
          "combinator": "and",
          "conditions": [
            {
              "id": "fb60c269-8e2f-4ba7-a278-4a0f7e8eb598",
              "operator": {
                "type": "string",
                "operation": "empty",
                "singleValue": true
              },
              "leftValue": "={{ $json.body.conversationHistory }}",
              "rightValue": ""
            }
          ]
        }
      },
      "typeVersion": 2.2
    },
    {
      "id": "8ed1f967-bc1a-4c47-bca9-bf3750d68dea",
      "name": "Merge",
      "type": "n8n-nodes-base.merge",
      "position": [
        688,
        -48
      ],
      "parameters": {},
      "typeVersion": 3.2
    },
    {
      "id": "79c3c250-b974-4094-af8c-a8c472071c8c",
      "name": "Basic LLM Chain",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "position": [
        912,
        -176
      ],
      "parameters": {
        "text": "={{ $json.prompt }}",
        "batching": {},
        "promptType": "define"
      },
      "typeVersion": 1.7
    },
    {
      "id": "874576cc-a94c-491f-a398-55821de46c6d",
      "name": "Google Gemini Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "position": [
        928,
        112
      ],
      "parameters": {
        "options": {}
      },
      "credentials": {
        "googlePalmApi": {
          "id": "a3qmkEPuRAKXTstM",
          "name": "Google Gemini(PaLM) Api account"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "29bf80c7-84d2-40de-a56f-ddf82b659273",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [
        1616,
        -176
      ],
      "parameters": {
        "options": {},
        "respondWith": "json",
        "responseBody": "={{ ({\n  \"question\": $json.newQuestion,\n  \"conversationHistory\": $json.updatedHistory\n}) }}"
      },
      "typeVersion": 1.4
    },
    {
      "id": "b533e3ac-7b58-4520-9e47-60ee8d3c01c3",
      "name": "Sticky Note",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -432,
        -144
      ],
      "parameters": {
        "width": 304,
        "height": 256,
        "content": "START HERE\nThis workflow starts when it receives a POST request from the frontend UI. It checks if it's the first question or a follow-up."
      },
      "typeVersion": 1
    },
    {
      "id": "c23be228-ded4-4b64-a69c-c73ddb5b1b26",
      "name": "Sticky Note1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        208,
        -400
      ],
      "parameters": {
        "color": 3,
        "content": "1. First Question\nIf it's the start of the interview, this node creates the initial prompt for the AI, using the resume text and job description sent from the UI."
      },
      "typeVersion": 1
    },
    {
      "id": "139ab288-03bb-40cf-bbe7-a95f57776d80",
      "name": "Sticky Note3",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        176,
        224
      ],
      "parameters": {
        "color": 5,
        "width": 352,
        "content": "2. Follow-up Question\nFor all subsequent turns, this node creates a different prompt that includes the conversation history, asking the AI for a logical follow-up question."
      },
      "typeVersion": 1
    },
    {
      "id": "e7752791-23d2-43df-8393-6f8268e6a901",
      "name": "Sticky Note2",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        928,
        -336
      ],
      "parameters": {
        "content": "3. AI Brain (Google Gemini)\nThe prompt is sent to the Google Gemini model to generate the interview question. Remember to add your own Google Gemini API credential here!"
      },
      "typeVersion": 1
    },
    {
      "id": "a8de54ce-397d-4ed4-aea1-f70baf730d05",
      "name": "Sticky Note4",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1280,
        192
      ],
      "parameters": {
        "color": 4,
        "content": "4. Send Response\nThese nodes prepare the AI's response and the updated conversation history, sending it all back to the frontend UI in a clean JSON format."
      },
      "typeVersion": 1
    },
    {
      "id": "6bc9a581-195d-46dc-88b4-b2721d088cc2",
      "name": "Create Initial Prompt",
      "type": "n8n-nodes-base.set",
      "position": [
        272,
        -240
      ],
      "parameters": {
        "options": {},
        "assignments": {
          "assignments": [
            {
              "id": "876f5f51-40d9-4f78-a820-f89e319389ec",
              "name": "prompt",
              "type": "string",
              "value": "=You are an expert technical recruiter named 'Alex'. You are conducting an interview for the position of '{{ $json.body.jobTitle }}'. Your task is to conduct a professional interview based *only* on the provided resume and job description.\n\nHere is the job description:\n\"\"\"\n{{ $json.body.jobDescription }}\n\"\"\"\n\nHere is the candidate's resume text:\n\"\"\"\n{{ $json.body.resumeText }}\n\"\"\"\n\nAsk the single, most impactful opening question. Ask only one question. Do not add any conversational filler.\n"
            }
          ]
        }
      },
      "typeVersion": 3.4
    },
    {
      "id": "f5ed22be-16b7-4bdc-b6c4-1310521110fa",
      "name": "Create Follow-up Prompt",
      "type": "n8n-nodes-base.set",
      "position": [
        288,
        80
      ],
      "parameters": {
        "options": {},
        "assignments": {
          "assignments": [
            {
              "id": "6de8f022-862c-4630-8a0f-bbddbe9681b3",
              "name": "prompt",
              "type": "string",
              "value": "=You are an expert technical recruiter named 'Alex', continuing an interview for '{{ $json.body.jobTitle }}'. The conversation history is below. Ask the next logical follow-up question based on the user's last answer. Do not repeat questions. Ask only one question.  CONVERSATION HISTORY: {{ $json.body.conversationHistory }}AI: {{ $json.body.lastQuestion }} User: {{ $json.body.answer }}"
            }
          ]
        }
      },
      "typeVersion": 3.4
    },
    {
      "id": "70021fa4-0326-4ee6-a5bf-518e6ecb030d",
      "name": "Prepare Response Data",
      "type": "n8n-nodes-base.set",
      "position": [
        1344,
        48
      ],
      "parameters": {
        "options": {},
        "assignments": {
          "assignments": [
            {
              "id": "6599f767-1863-47df-b4b3-3a3d4999a287",
              "name": "newQuestion",
              "type": "string",
              "value": "={{ $('Basic LLM Chain').item.json.text }}"
            },
            {
              "id": "b6955598-7a22-4e67-ad57-b4c000872d74",
              "name": "updatedHistory",
              "type": "string",
              "value": "={{ $('Webhook').item.json.body.conversationHistory || '' }}AI: {{ $json.newQuestion }}\\nUser:"
            }
          ]
        }
      },
      "typeVersion": 3.4
    },
    {
      "id": "b9162dfe-4159-472f-a928-665d2146fdf1",
      "name": "Sticky Note5",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -1168,
        -576
      ],
      "parameters": {
        "color": 5,
        "width": 528,
        "height": 832,
        "content": "What does this workflow do?\nThis workflow acts as the backend \"brain\" for a sophisticated AI Voice Interviewer. It receives a user's resume text and a target job description, then uses a Large Language Model (LLM) to conduct a realistic, voice-based interview. The workflow maintains conversation history to ask relevant follow-up questions, creating a dynamic and personalized interview practice experience.\n\nThis template is designed to work with a simple HTML frontend that handles the voice-to-text and text-to-speech functionality.\n\nWhat services does this workflow use?\nGoogle Gemini: This is the LLM used to generate intelligent interview questions. You can easily swap this out for other models like OpenAI.\n\nWhat credentials do you need to have?\nYou will need one credential:\n\nA Google Gemini API Key. You can get one for free from the Google AI Studio.\n\nHow to use this workflow\nThis workflow is the backend and requires a frontend to interact with.\n\nSet up the Frontend: You can find the complete frontend code and setup instructions in this GitHub repository.\n\nConfigure Credentials: In this n8n workflow, click on the \"Google Gemini Chat Model\" node and add your own Gemini API credential.\n\nActivate the Workflow: Make sure the workflow is saved and active.\n\nConnect Frontend to Backend: Click on the \"Webhook\" node and copy the Production URL. Paste this URL into the voice-interview.html page as instructed in the GitHub repository's README.md file.\n\nStart Interviewing: Fill out the form on the web page to begin your voice interview!"
      },
      "typeVersion": 1
    }
  ],
  "active": true,
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "18020fc0-129a-4b7c-8c57-175011e4a81f",
  "connections": {
    "If": {
      "main": [
        [
          {
            "node": "Create Initial Prompt",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Create Follow-up Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Webhook": {
      "main": [
        [
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain": {
      "main": [
        [
          {
            "node": "Prepare Response Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Initial Prompt": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Response Data": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Create Follow-up Prompt": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Google Gemini Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    }
  },
  "_metadata": {
    "name": "Practice Job Interviews with Voice-based Google Gemini AI Interviewer",
    "used_count": 0,
    "popularity_score": 25,
    "source_url": "https://n8n.io/workflows/6614",
    "scraped_at": "2025-08-21 04:23:27",
    "workflow_id": "170fdfbe-33ea-5b55-897d-ee4de397cb1a"
  },
  "_filename": "Practice_Job_Interviews_with_Voice_based_Google_Gemini_AI_Interviewer.json"
}