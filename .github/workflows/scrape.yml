name: Scrape n8n Workflows

on:
  workflow_dispatch:
    inputs:
      max_workflows:
        description: 'Maximum number of workflows to scrape'
        required: false
        default: '10'
        type: string
      scrape_delay:
        description: 'Delay between scrapes (seconds)'
        required: false
        default: '5'
        type: string

jobs:
  scrape-workflows:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install Chrome
      run: |
        wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
        echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install selenium requests PyGithub python-dotenv
        
    - name: Create directories
      run: |
        mkdir -p workflows indexes scripts
        
    - name: Copy scraper script
      run: |
        cp scripts/scrape_workflows.py ./scrape_workflows.py
        
    - name: Set up environment
      run: |
        echo "GITHUB_TOKEN=${{ secrets.GITHUB_TOKEN }}" >> $GITHUB_ENV
        echo "GITHUB_REPO=${{ github.repository }}" >> $GITHUB_ENV
        echo "MAX_WORKFLOWS=${{ github.event.inputs.max_workflows }}" >> $GITHUB_ENV
        echo "SCRAPE_DELAY=${{ github.event.inputs.scrape_delay }}" >> $GITHUB_ENV
        
    - name: Get existing workflows
      id: existing
      run: |
        if [ -d "workflows" ]; then
          echo "existing_count=$(ls workflows/*.json 2>/dev/null | wc -l)" >> $GITHUB_OUTPUT
          echo "existing_files=$(ls workflows/*.json 2>/dev/null | xargs -n 1 basename | jq -R -s -c 'split("\n")[:-1]')" >> $GITHUB_OUTPUT
        else
          echo "existing_count=0" >> $GITHUB_OUTPUT
          echo "existing_files=[]" >> $GITHUB_OUTPUT
        fi
        
    - name: Scrape workflows
      run: |
        echo "🚀 Starting workflow scraping..."
        echo "📊 Existing workflows: ${{ steps.existing.outputs.existing_count }}"
        echo "📋 Max workflows to scrape: ${{ github.event.inputs.max_workflows }}"
        echo "⏱️  Scrape delay: ${{ github.event.inputs.scrape_delay }}s"
        
        python scrape_workflows.py
        
    - name: Generate indexes
      run: |
        echo "📊 Generating indexes..."
        python scripts/generate_indexes.py
        
    - name: Get new workflow count
      id: new_count
      run: |
        new_count=$(ls workflows/*.json 2>/dev/null | wc -l)
        echo "new_count=$new_count" >> $GITHUB_OUTPUT
        
    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        git add workflows/ indexes/
        git status
        
        if git diff --staged --quiet; then
          echo "No new workflows to commit"
        else
          git commit -m "🤖 Auto-scrape: Added ${{ steps.new_count.outputs.new_count }} new workflows [skip ci]"
          git push
        fi
        
    - name: Create summary
      run: |
        echo "## 📊 Scraping Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Existing workflows:** ${{ steps.existing.outputs.existing_count }}" >> $GITHUB_STEP_SUMMARY
        echo "- **New workflows:** ${{ steps.new_count.outputs.new_count }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Total workflows:** $(ls workflows/*.json 2>/dev/null | wc -l)" >> $GITHUB_STEP_SUMMARY
        echo "- **Indexes generated:** 4 (manifest, categories, quality, integrations)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 🔍 New Workflows:" >> $GITHUB_STEP_SUMMARY
        if [ -d "workflows" ]; then
          ls -la workflows/*.json | tail -n +2 | while read line; do
            filename=$(echo "$line" | awk '{print $9}' | xargs basename)
            echo "- $filename" >> $GITHUB_STEP_SUMMARY
          done
        fi
